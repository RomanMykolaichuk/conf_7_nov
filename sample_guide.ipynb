{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Огляд використаних технологій\n",
    "\n",
    "Цей проєкт побудовано на сучасних інструментах та технологіях для роботи з мовними моделями, що дозволяє автоматизувати генерацію текстових відповідей на запити, пов'язані з дистанційним навчанням. Нижче наведено огляд основних технологій, використаних у цьому проєкті:\n",
    "\n",
    "1. **Мовна модель Ollama (Llama 3.1)**:\n",
    "   - **Ollama** – це інтерфейс для роботи з мовними моделями, що дозволяє отримувати текстові відповіді на основі введеного запиту. Версія моделі Llama 3.1 забезпечує високу якість генерації тексту та гнучкість у налаштуваннях, таких як максимальний час обробки запиту.\n",
    "   - **Llama 3.1** використовується для генерації змістовних відповідей на запити, формулювання навчальних матеріалів та відповіді на складні питання в простій і зрозумілій формі.\n",
    "\n",
    "2. **Бібліотека `llama_index`**:\n",
    "   - `llama_index` забезпечує зручний доступ до моделей, таких як Ollama, що полегшує інтеграцію мовної моделі в Python проєкт. Вона також підтримує основні функції для обробки запитів і налаштування параметрів.\n",
    "   - Через цю бібліотеку ми маємо можливість налаштовувати модель, обмежуючи час очікування відповіді або адаптуючи запити під специфічні завдання.\n",
    "\n",
    "3. **Python бібліотека `os`**:\n",
    "   - Бібліотека `os` надає функції для роботи з операційною системою та керування змінними середовища. У проєкті вона використовується для налаштування ключів API, що дозволяє безпечно інтегрувати модель у середовище виконання коду.\n",
    "\n",
    "4. **Jupyter Notebook та магічна команда `%pip`**:\n",
    "   - **Jupyter Notebook** використовується як основне середовище для інтерактивного виконання коду, що дозволяє створювати, тестувати й переглядати результати виконання запитів в реальному часі.\n",
    "   - **%pip install** – магічна команда, яка дозволяє встановити всі залежності в середовищі Jupyter Notebook без необхідності переходу в інші інструменти або командний рядок.\n",
    "\n",
    "5. **Цикл `for` для багатозапитної обробки**:\n",
    "   - Використання циклів дозволяє автоматизувати обробку кількох запитів, які модифікуються одним набором параметрів, наприклад, обмеженням на кількість слів у відповіді. Це дозволяє швидко згенерувати серію відповідей на різні запити в одному циклі, що значно підвищує ефективність проєкту.\n",
    "\n",
    "6. **Обробка винятків (Exception Handling)**:\n",
    "   - Важливим аспектом проєкту є обробка можливих помилок під час виконання запитів. Використовуючи конструкцію `try-except`, ми можемо обробляти непередбачені ситуації та уникати переривання роботи програми у разі виникнення помилок.\n",
    "\n",
    "### Загальна схема роботи проєкту\n",
    "\n",
    "1. **Ініціалізація та налаштування мовної моделі**: Створюється екземпляр моделі Llama 3.1, яка використовується для обробки текстових запитів.\n",
    "2. **Створення запитів та обробка**: Формуються запити з різних тематик у сфері дистанційного навчання, і модель генерує текстові відповіді на кожен із запитів.\n",
    "3. **Автоматизація процесу**: Використання циклу дозволяє зручно обробляти великий набір запитів із заданими обмеженнями, такими як обмеження на кількість слів у відповіді.\n",
    "4. **Виведення та збереження результатів**: Кожна відповідь виводиться на екран і може бути додатково збережена або використана для аналізу.\n",
    "\n",
    "### Висновок\n",
    "\n",
    "Завдяки поєднанню мовної моделі, бібліотек Python та інтерактивного середовища Jupyter Notebook, цей проєкт дозволяє ефективно працювати з текстом, автоматизуючи генерацію відповідей на різноманітні питання. Він також демонструє можливість адаптації сучасних інструментів штучного інтелекту для потреб дистанційного навчання."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вступ\n",
    "\n",
    "Цей проєкт використовує мовну модель Ollama (версія Llama 3.1) для обробки природної мови, що дозволяє створювати текстові відповіді на запити українською мовою. Інструмент Ollama надає можливість налаштування мовної моделі через параметри, а також забезпечує достатню гнучкість для роботи з текстом різної складності. Нижче подані пояснення до кожної клітинки коду для розуміння процесу налаштування та виклику моделі.\n",
    "\n",
    "---\n",
    "\n",
    "### Markdown Cell 1: Імпорт бібліотеки та налаштування ключа API\n",
    "\n",
    "```python\n",
    "# import os\n",
    "\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"NA\"\n",
    "```\n",
    "\n",
    "#### Пояснення\n",
    "\n",
    "Цей блок коду використовується для імпорту бібліотеки `os`, яка дозволяє керувати змінними середовища, і налаштування змінної `OPENAI_API_KEY` для доступу до API OpenAI. Цей рядок коду закоментовано, щоб уникнути проблем із відкритим зберіганням ключа API, але його можна розкоментувати та встановити ключ для підключення до OpenAI API або подібних платформ.\n",
    "\n",
    "---\n",
    "\n",
    "### Markdown Cell 2: Встановлення необхідних пакетів\n",
    "\n",
    "```python\n",
    "%pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "#### Пояснення\n",
    "\n",
    "Команда `%pip install` використовується для встановлення бібліотек, зазначених у файлі `requirements.txt`, безпосередньо в середовищі Jupyter Notebook. Це дозволяє переконатися, що всі необхідні залежності для роботи з моделлю Ollama встановлені та доступні в середовищі."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Markdown Cell 3: Імпорт моделі Ollama та налаштування параметрів\n",
    "\n",
    "```python\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.core import Settings\n",
    "\n",
    "llm = Ollama(model=\"llama3.1\", request_timeout=400.0)\n",
    "```\n",
    "\n",
    "#### Пояснення\n",
    "\n",
    "1. **Імпорт Ollama** – модель Ollama імпортується з бібліотеки `llama_index`, що забезпечує доступ до мовної моделі Llama 3.1.\n",
    "2. **Імпорт Settings** – `Settings` імпортується для можливого налаштування параметрів, таких як тайм-аути запитів або інші конфігурації.\n",
    "3. **llm = Ollama(model=\"llama3.1\", request_timeout=400.0)** – цей рядок ініціалізує об'єкт `llm`, який представляє модель Llama 3.1:\n",
    "   - **model=\"llama3.1\"** – вказує, яка саме версія моделі буде використана.\n",
    "   - **request_timeout=400.0** – встановлює час очікування (в секундах) для обробки запиту, щоб уникнути переривання через тривалий час обробки.\n",
    "\n",
    "Цей блок коду налаштовує модель Ollama для подальшого використання при генерації відповідей.\n",
    "\n",
    "---\n",
    "\n",
    "### Markdown Cell 4: Виклик моделі для генерації відповіді на запит\n",
    "\n",
    "```python\n",
    "response = llm.complete(\"Хто такий Валерій Залужний. Надай відповідь до 10 слів українською мовою\")\n",
    "print(response)\n",
    "```\n",
    "\n",
    "#### Пояснення\n",
    "\n",
    "Цей блок коду демонструє, як використовувати налаштовану модель для генерації короткої текстової відповіді:\n",
    "\n",
    "1. **Запит до моделі** – рядок `\"Хто такий Валерій Залужний. Надай відповідь до 10 слів українською мовою\"` передається моделі як запит для генерації відповіді.\n",
    "2. **llm.complete(prompt)** – метод `complete` обробляє вхідний запит та повертає результат.\n",
    "3. **print(response)** – виводить відповідь моделі на екран.\n",
    "\n",
    "Цей приклад показує, як модель може використовуватися для швидкого отримання інформації за конкретними запитами."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Markdown Cell 5: Використання моделі для створення тексту на задану тему\n",
    "\n",
    "```python\n",
    "prompt = \"Using AI in education - main directions of use. Write in 100 words\"\n",
    "response = llm.complete(prompt)\n",
    "print(response)\n",
    "```\n",
    "\n",
    "#### Пояснення\n",
    "\n",
    "Цей блок демонструє, як можна використовувати модель для генерації більш розгорнутого тексту на задану тему.\n",
    "\n",
    "1. **prompt** – змінна `prompt` містить запит: \"Using AI in education - main directions of use. Write in 100 words\", що означає, що модель повинна створити текст на тему використання ШІ в освіті, обмежившись 100 словами.\n",
    "2. **llm.complete(prompt)** – метод `complete` обробляє вміст `prompt` і генерує відповідь на основі запиту.\n",
    "3. **print(response)** – виводить згенерований текст, що стосується напрямків використання ШІ в освіті.\n",
    "\n",
    "Цей приклад ілюструє можливості моделі для створення текстових відповідей на основі теми чи питання, заданого користувачем."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Markdown Cell 6: Приклади запитів у сфері використання ШІ в дистанційному навчанні\n",
    "\n",
    "Цей блок коду показує, як можна використовувати модель для генерації відповідей на серію запитів, що стосуються застосування штучного інтелекту в дистанційному навчанні. Кожен запит фокусується на різних аспектах, таких як персоналізація навчання, моніторинг прогресу, етика та адаптивне тестування.\n",
    "\n",
    "```python\n",
    "# Деякі приклади запитів у сфері використання AI в дистанційному навчанні (DL)\n",
    "prompts = [\n",
    "    \"How can AI personalize learning experiences in distance education?\",\n",
    "    \"Explain the role of AI in monitoring student progress in online courses.\",\n",
    "    \"What are the benefits of using AI-driven chatbots for student support in DL?\",\n",
    "    \"How can AI help identify at-risk students in distance learning environments?\",\n",
    "    \"Discuss the use of natural language processing in automated assessment in DL.\",\n",
    "    \"How can AI-driven analytics improve student engagement in online education?\",\n",
    "    \"Explain how generative AI can create interactive learning content for DL.\",\n",
    "    \"What are the ethical concerns of using AI in distance learning platforms?\",\n",
    "    \"How can AI be used to provide feedback to students in real-time?\",\n",
    "    \"Discuss the potential of AI in adaptive testing for online education.\"\n",
    "]\n",
    "words_count = 200\n",
    "afterprompt = f\" Use no more than {words_count} words\"\n",
    "\n",
    "# Виконання запитів та вивід відповідей\n",
    "for prompt in prompts:\n",
    "    try:\n",
    "        response = llm.complete(prompt + afterprompt)\n",
    "        print(f\"Prompt: {prompt}\\nResponse: {response}\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred for prompt: '{prompt}'. Error: {str(e)}\")\n",
    "```\n",
    "\n",
    "#### Пояснення\n",
    "\n",
    "1. **prompts** – список запитів, що стосуються різних аспектів застосування штучного інтелекту в дистанційному навчанні (DL).\n",
    "2. **words_count** – змінна, що встановлює обмеження на кількість слів у відповіді.\n",
    "3. **afterprompt** – текст, що додається до кожного запиту, щоб обмежити довжину відповіді до 200 слів.\n",
    "4. **Цикл for** – виконує кожен запит у списку `prompts`:\n",
    "   - **llm.complete(prompt + afterprompt)** – метод `complete` обробляє запит і повертає відповідь, обмежену 200 словами.\n",
    "   - **print** – виводить запит і відповідь на екран, що дозволяє побачити кожну згенеровану відповідь окремо.\n",
    "   - **Exception handling** – у разі виникнення помилки, наприклад, якщо запит не вдалося обробити, виводиться повідомлення з описом помилки.\n",
    "\n",
    "Цей приклад демонструє, як можна автоматично генерувати відповіді на серію запитів, що стосуються конкретної тематики. Такий підхід дозволяє отримати структуровані відповіді, корисні для дослідження теми або підготовки навчальних матеріалів з використанням штучного інтелекту в освіті."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загальні висновки\n",
    "\n",
    "Проєкт продемонстрував ефективність використання сучасних мовних моделей для автоматизації генерації текстових відповідей на запити, що охоплюють різні аспекти дистанційного навчання. Використання моделі Llama 3.1 через платформу Ollama забезпечило отримання змістовних та інформативних відповідей, що можуть бути корисними для освітніх матеріалів, досліджень та інших цілей. Основні результати та переваги проєкту включають:\n",
    "\n",
    "1. **Автоматизація процесу**:\n",
    "   - Використання циклу `for` дозволило зручно обробити великий набір запитів з мінімальними витратами часу, автоматизуючи процес отримання відповідей. Це особливо корисно для освітніх установ, де можна швидко створювати навчальні матеріали або аналітичні звіти на основі автоматизованих запитів.\n",
    "\n",
    "2. **Інтеграція мовної моделі в освітні проєкти**:\n",
    "   - Завдяки можливостям мовної моделі, проєкт може автоматично генерувати відповіді, що охоплюють складні теми, та адаптувати їх для широкої аудиторії. Це відкриває нові можливості для застосування штучного інтелекту в освіті, від автоматизованого оцінювання до створення персоналізованих навчальних курсів.\n",
    "\n",
    "3. **Гнучкість у налаштуванні параметрів**:\n",
    "   - Налаштування тайм-аутів запитів та обмежень на кількість слів у відповіді дозволило адаптувати модель під різні типи запитів, від коротких відповідей до розширених текстів. Це допомагає отримувати чіткі та релевантні результати відповідно до специфічних вимог.\n",
    "\n",
    "4. **Можливість обробки великих обсягів інформації**:\n",
    "   - Модель може обробляти великі обсяги тексту за короткий час, що корисно для дослідників і аналітиків, які працюють із великими наборами даних. Такий підхід значно підвищує продуктивність і полегшує аналіз інформації.\n",
    "\n",
    "5. **Безпека та збереження ключових даних**:\n",
    "   - Використання змінних середовища для зберігання ключів API гарантує безпечне зберігання конфіденційної інформації, що є важливим аспектом при роботі з API та обробкою даних у хмарних середовищах.\n",
    "\n",
    "### Підсумок\n",
    "\n",
    "Проєкт показує, як сучасні мовні моделі можуть змінити підхід до створення текстових матеріалів, особливо в освітньому середовищі. Поєднання технологій для автоматизації текстової генерації, збереження безпеки даних та налаштувань для персоналізації результатів відкриває нові можливості для використання штучного інтелекту в навчанні та дослідженнях."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
